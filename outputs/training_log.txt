[INFO] Training model...

Epoch 1/100
482/482 - 3s - 6ms/step - loss: 0.3845 - mae: 0.3909 - val_loss: 0.3470 - val_mae: 0.3180 - learning_rate: 1.0000e-03
Epoch 2/100
482/482 - 2s - 4ms/step - loss: 0.2675 - mae: 0.3098 - val_loss: 0.3450 - val_mae: 0.3274 - learning_rate: 1.0000e-03
Epoch 3/100
482/482 - 2s - 4ms/step - loss: 0.2478 - mae: 0.2964 - val_loss: 0.3180 - val_mae: 0.2940 - learning_rate: 1.0000e-03
Epoch 4/100
482/482 - 2s - 4ms/step - loss: 0.2334 - mae: 0.2858 - val_loss: 0.3610 - val_mae: 0.3577 - learning_rate: 1.0000e-03
Epoch 5/100
482/482 - 2s - 4ms/step - loss: 0.2229 - mae: 0.2773 - val_loss: 0.2984 - val_mae: 0.2770 - learning_rate: 1.0000e-03
Epoch 6/100
482/482 - 2s - 4ms/step - loss: 0.2205 - mae: 0.2751 - val_loss: 0.3885 - val_mae: 0.3735 - learning_rate: 1.0000e-03
Epoch 7/100
482/482 - 2s - 4ms/step - loss: 0.2199 - mae: 0.2735 - val_loss: 0.3069 - val_mae: 0.3057 - learning_rate: 1.0000e-03
Epoch 8/100
482/482 - 2s - 4ms/step - loss: 0.2175 - mae: 0.2719 - val_loss: 0.3007 - val_mae: 0.3014 - learning_rate: 1.0000e-03
Epoch 9/100
482/482 - 2s - 4ms/step - loss: 0.2157 - mae: 0.2700 - val_loss: 0.2878 - val_mae: 0.2830 - learning_rate: 1.0000e-03
Epoch 10/100
482/482 - 2s - 4ms/step - loss: 0.2142 - mae: 0.2694 - val_loss: 0.2842 - val_mae: 0.2745 - learning_rate: 1.0000e-03
Epoch 11/100
482/482 - 2s - 4ms/step - loss: 0.2090 - mae: 0.2654 - val_loss: 0.3382 - val_mae: 0.3484 - learning_rate: 1.0000e-03
Epoch 12/100
482/482 - 2s - 5ms/step - loss: 0.2117 - mae: 0.2668 - val_loss: 0.3046 - val_mae: 0.3114 - learning_rate: 1.0000e-03
Epoch 13/100
482/482 - 2s - 5ms/step - loss: 0.2084 - mae: 0.2647 - val_loss: 0.2946 - val_mae: 0.2864 - learning_rate: 1.0000e-03
Epoch 14/100
482/482 - 2s - 4ms/step - loss: 0.2119 - mae: 0.2676 - val_loss: 0.2760 - val_mae: 0.2654 - learning_rate: 1.0000e-03
Epoch 15/100
482/482 - 2s - 4ms/step - loss: 0.2048 - mae: 0.2626 - val_loss: 0.2842 - val_mae: 0.2778 - learning_rate: 1.0000e-03
Epoch 16/100
482/482 - 2s - 4ms/step - loss: 0.2050 - mae: 0.2631 - val_loss: 0.3286 - val_mae: 0.3321 - learning_rate: 1.0000e-03
Epoch 17/100
482/482 - 2s - 4ms/step - loss: 0.2107 - mae: 0.2667 - val_loss: 0.2880 - val_mae: 0.2900 - learning_rate: 1.0000e-03
Epoch 18/100
482/482 - 2s - 4ms/step - loss: 0.2097 - mae: 0.2653 - val_loss: 0.3465 - val_mae: 0.3512 - learning_rate: 1.0000e-03
Epoch 19/100

Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
482/482 - 2s - 5ms/step - loss: 0.2048 - mae: 0.2629 - val_loss: 0.2777 - val_mae: 0.2666 - learning_rate: 1.0000e-03
Epoch 20/100
482/482 - 2s - 4ms/step - loss: 0.1944 - mae: 0.2541 - val_loss: 0.2768 - val_mae: 0.2739 - learning_rate: 5.0000e-04
Epoch 21/100
482/482 - 2s - 4ms/step - loss: 0.1932 - mae: 0.2536 - val_loss: 0.2904 - val_mae: 0.3007 - learning_rate: 5.0000e-04
Epoch 22/100
482/482 - 2s - 4ms/step - loss: 0.1917 - mae: 0.2528 - val_loss: 0.2736 - val_mae: 0.2738 - learning_rate: 5.0000e-04
Epoch 23/100
482/482 - 2s - 5ms/step - loss: 0.1910 - mae: 0.2523 - val_loss: 0.2783 - val_mae: 0.2935 - learning_rate: 5.0000e-04
Epoch 24/100
482/482 - 2s - 4ms/step - loss: 0.1898 - mae: 0.2515 - val_loss: 0.2801 - val_mae: 0.2883 - learning_rate: 5.0000e-04
Epoch 25/100
482/482 - 2s - 5ms/step - loss: 0.1917 - mae: 0.2522 - val_loss: 0.2722 - val_mae: 0.2723 - learning_rate: 5.0000e-04
Epoch 26/100
482/482 - 2s - 5ms/step - loss: 0.1878 - mae: 0.2503 - val_loss: 0.2904 - val_mae: 0.3047 - learning_rate: 5.0000e-04
Epoch 27/100
482/482 - 2s - 5ms/step - loss: 0.1906 - mae: 0.2523 - val_loss: 0.2814 - val_mae: 0.2974 - learning_rate: 5.0000e-04
Epoch 28/100
482/482 - 2s - 4ms/step - loss: 0.1913 - mae: 0.2520 - val_loss: 0.2751 - val_mae: 0.2804 - learning_rate: 5.0000e-04
Epoch 29/100
482/482 - 3s - 5ms/step - loss: 0.1890 - mae: 0.2509 - val_loss: 0.2701 - val_mae: 0.2612 - learning_rate: 5.0000e-04
Epoch 30/100
482/482 - 2s - 5ms/step - loss: 0.1876 - mae: 0.2503 - val_loss: 0.2690 - val_mae: 0.2667 - learning_rate: 5.0000e-04
Epoch 31/100
482/482 - 2s - 5ms/step - loss: 0.1867 - mae: 0.2493 - val_loss: 0.2901 - val_mae: 0.3060 - learning_rate: 5.0000e-04
Epoch 32/100
482/482 - 2s - 4ms/step - loss: 0.1891 - mae: 0.2507 - val_loss: 0.2705 - val_mae: 0.2739 - learning_rate: 5.0000e-04
Epoch 33/100
482/482 - 2s - 4ms/step - loss: 0.1862 - mae: 0.2495 - val_loss: 0.2756 - val_mae: 0.2774 - learning_rate: 5.0000e-04
Epoch 34/100
482/482 - 3s - 5ms/step - loss: 0.1826 - mae: 0.2468 - val_loss: 0.2729 - val_mae: 0.2580 - learning_rate: 5.0000e-04
Epoch 35/100
482/482 - 2s - 4ms/step - loss: 0.1865 - mae: 0.2489 - val_loss: 0.2687 - val_mae: 0.2646 - learning_rate: 5.0000e-04
Epoch 36/100
482/482 - 2s - 4ms/step - loss: 0.1843 - mae: 0.2482 - val_loss: 0.2760 - val_mae: 0.2758 - learning_rate: 5.0000e-04
Epoch 37/100
482/482 - 2s - 4ms/step - loss: 0.1866 - mae: 0.2491 - val_loss: 0.2866 - val_mae: 0.3063 - learning_rate: 5.0000e-04
Epoch 38/100
482/482 - 2s - 5ms/step - loss: 0.1863 - mae: 0.2490 - val_loss: 0.2724 - val_mae: 0.2716 - learning_rate: 5.0000e-04
Epoch 39/100
482/482 - 2s - 4ms/step - loss: 0.1828 - mae: 0.2478 - val_loss: 0.2696 - val_mae: 0.2585 - learning_rate: 5.0000e-04
Epoch 40/100

Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
482/482 - 2s - 4ms/step - loss: 0.1831 - mae: 0.2477 - val_loss: 0.2755 - val_mae: 0.2776 - learning_rate: 5.0000e-04
Epoch 41/100
482/482 - 2s - 5ms/step - loss: 0.1790 - mae: 0.2437 - val_loss: 0.2692 - val_mae: 0.2683 - learning_rate: 2.5000e-04
Epoch 42/100
482/482 - 2s - 5ms/step - loss: 0.1760 - mae: 0.2418 - val_loss: 0.2704 - val_mae: 0.2774 - learning_rate: 2.5000e-04
Epoch 43/100
482/482 - 2s - 5ms/step - loss: 0.1762 - mae: 0.2425 - val_loss: 0.2687 - val_mae: 0.2720 - learning_rate: 2.5000e-04
Epoch 44/100
482/482 - 2s - 5ms/step - loss: 0.1769 - mae: 0.2423 - val_loss: 0.2759 - val_mae: 0.2879 - learning_rate: 2.5000e-04
Epoch 45/100

Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
482/482 - 2s - 5ms/step - loss: 0.1764 - mae: 0.2426 - val_loss: 0.2701 - val_mae: 0.2655 - learning_rate: 2.5000e-04
Epoch 46/100
482/482 - 2s - 5ms/step - loss: 0.1732 - mae: 0.2394 - val_loss: 0.2666 - val_mae: 0.2521 - learning_rate: 1.2500e-04
Epoch 47/100
482/482 - 2s - 5ms/step - loss: 0.1733 - mae: 0.2400 - val_loss: 0.2812 - val_mae: 0.2955 - learning_rate: 1.2500e-04
Epoch 48/100
482/482 - 2s - 5ms/step - loss: 0.1713 - mae: 0.2395 - val_loss: 0.2686 - val_mae: 0.2702 - learning_rate: 1.2500e-04
Epoch 49/100
482/482 - 3s - 6ms/step - loss: 0.1719 - mae: 0.2393 - val_loss: 0.2673 - val_mae: 0.2612 - learning_rate: 1.2500e-04
Epoch 50/100
482/482 - 2s - 4ms/step - loss: 0.1719 - mae: 0.2387 - val_loss: 0.2671 - val_mae: 0.2556 - learning_rate: 1.2500e-04
Epoch 51/100

Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
482/482 - 2s - 4ms/step - loss: 0.1707 - mae: 0.2384 - val_loss: 0.2738 - val_mae: 0.2834 - learning_rate: 1.2500e-04
Epoch 52/100
482/482 - 2s - 5ms/step - loss: 0.1710 - mae: 0.2382 - val_loss: 0.2655 - val_mae: 0.2552 - learning_rate: 6.2500e-05
Epoch 53/100
482/482 - 3s - 6ms/step - loss: 0.1707 - mae: 0.2379 - val_loss: 0.2696 - val_mae: 0.2769 - learning_rate: 6.2500e-05
Epoch 54/100
482/482 - 3s - 7ms/step - loss: 0.1677 - mae: 0.2364 - val_loss: 0.2679 - val_mae: 0.2726 - learning_rate: 6.2500e-05
Epoch 55/100
482/482 - 3s - 5ms/step - loss: 0.1693 - mae: 0.2369 - val_loss: 0.2717 - val_mae: 0.2824 - learning_rate: 6.2500e-05
Epoch 56/100
482/482 - 3s - 6ms/step - loss: 0.1686 - mae: 0.2369 - val_loss: 0.2649 - val_mae: 0.2578 - learning_rate: 6.2500e-05
Epoch 57/100
482/482 - 3s - 7ms/step - loss: 0.1695 - mae: 0.2371 - val_loss: 0.2685 - val_mae: 0.2738 - learning_rate: 6.2500e-05
Epoch 58/100
482/482 - 3s - 6ms/step - loss: 0.1683 - mae: 0.2369 - val_loss: 0.2662 - val_mae: 0.2636 - learning_rate: 6.2500e-05
Epoch 59/100
482/482 - 3s - 6ms/step - loss: 0.1691 - mae: 0.2370 - val_loss: 0.2663 - val_mae: 0.2672 - learning_rate: 6.2500e-05
Epoch 60/100
482/482 - 3s - 5ms/step - loss: 0.1676 - mae: 0.2363 - val_loss: 0.2742 - val_mae: 0.2872 - learning_rate: 6.2500e-05
Epoch 61/100

Epoch 61: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
482/482 - 3s - 7ms/step - loss: 0.1690 - mae: 0.2364 - val_loss: 0.2664 - val_mae: 0.2675 - learning_rate: 6.2500e-05
Epoch 62/100
482/482 - 2s - 5ms/step - loss: 0.1663 - mae: 0.2352 - val_loss: 0.2658 - val_mae: 0.2632 - learning_rate: 3.1250e-05
Epoch 63/100
482/482 - 3s - 5ms/step - loss: 0.1679 - mae: 0.2361 - val_loss: 0.2703 - val_mae: 0.2794 - learning_rate: 3.1250e-05
Epoch 64/100
482/482 - 2s - 5ms/step - loss: 0.1678 - mae: 0.2355 - val_loss: 0.2676 - val_mae: 0.2739 - learning_rate: 3.1250e-05
Epoch 65/100
482/482 - 2s - 4ms/step - loss: 0.1680 - mae: 0.2362 - val_loss: 0.2651 - val_mae: 0.2630 - learning_rate: 3.1250e-05
Epoch 66/100

Epoch 66: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
482/482 - 2s - 4ms/step - loss: 0.1659 - mae: 0.2351 - val_loss: 0.2650 - val_mae: 0.2618 - learning_rate: 3.1250e-05

[INFO] Final Loss (MSE): 0.1343
[INFO] Final MAE: 0.1988 km/h
[INFO] Loss plot saved at /home/darime/outputs/loss_plot.png
[INFO] MAE plot saved at /home/darime/outputs/mae_plot.png
